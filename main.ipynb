{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pymupdf\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "from thefuzz import fuzz\n",
    "from collections import defaultdict\n",
    "\n",
    "# open input PDF \n",
    "doc=pymupdf.open(\"examples/input/input5.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read OpenAI API key and assistant ID from .env. Hint: Use python-dotenv\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_ASST_ID = os.getenv(\"OPENAI_ASST_ID\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bounding_boxes(words_to_highlight):\n",
    "\n",
    "    # Assuming words_to_highlight is defined\n",
    "    # words_to_highlight = [...]  # your list of tuples\n",
    "\n",
    "    # Step 1: Group words by line index (assuming the line index is at position 6)\n",
    "    lines = defaultdict(list)\n",
    "    blocks = defaultdict(list)\n",
    "    for word in words_to_highlight:\n",
    "        line_index = word[6]\n",
    "        blocks[word[5]].append(line_index)\n",
    "        lines[line_index].append(word)\n",
    "\n",
    "    # Step 2: For each line, find the bounding box\n",
    "    line_bounding_boxes = {}\n",
    "    for line_index, words in lines.items():\n",
    "        min_x = min(word[0] for word in words)\n",
    "        min_y = min(word[1] for word in words)\n",
    "        max_x = max(word[2] for word in words)\n",
    "        max_y = max(word[3] for word in words)\n",
    "        line_bounding_boxes[line_index] = (min_x, min_y, max_x, max_y)\n",
    "\n",
    "    return line_bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_words_to_highlight(sentence, word_tuples, grace_period_counter):\n",
    "\n",
    "    sentence_words = sentence.split(\" \")\n",
    "\n",
    "    # List to store words to highlight\n",
    "    words_to_highlight = []\n",
    "\n",
    "    init_grace_period_counter = grace_period_counter\n",
    "\n",
    "    # Pointer to the current word in the sentence\n",
    "    sentence_pointer = 0\n",
    "\n",
    "    max_word_distance = 15\n",
    "    words_passed = 0\n",
    "    in_matching = False\n",
    "\n",
    "    # Iterator for word tuples\n",
    "    i = 0\n",
    "    while i < len(word_tuples):\n",
    "        word_in_tuple = word_tuples[i][4]  # The word is at index 4\n",
    "        \n",
    "        # Check if the word ends with a hyphen\n",
    "        if (word_in_tuple.endswith('-') or word_in_tuple.endswith('â€”')) and (i + 1) < len(word_tuples):\n",
    "            # Get the next word and concatenate\n",
    "            next_word_in_tuple = word_tuples[i + 1][4]\n",
    "\n",
    "            concatenated_word = word_in_tuple[:-1] + next_word_in_tuple  # Remove the hyphen before concatenating\n",
    "\n",
    "            # Check if the concatenated word matches the current word in the sentence\n",
    "            if sentence_pointer < len(sentence_words) and fuzz.token_sort_ratio(concatenated_word, sentence_words[sentence_pointer]) >= 80:\n",
    "                # Add both parts to the highlight list\n",
    "                in_matching = True\n",
    "                words_to_highlight.append(word_tuples[i])\n",
    "                words_to_highlight.append(word_tuples[i + 1])\n",
    "                sentence_pointer += 1  # Move to the next word in the sentence\n",
    "                i += 1  # Skip the next tuple since it was already used\n",
    "                \n",
    "            else:\n",
    "\n",
    "                words_passed += 1\n",
    "\n",
    "                if (in_matching and words_passed > max_word_distance) or (grace_period_counter > 0):\n",
    "                    sentence_pointer = 0\n",
    "                    grace_period_counter = init_grace_period_counter  # Reset the grace period\n",
    "                    words_to_highlight = []\n",
    "                    \n",
    "                    in_matching = False\n",
    "                    words_passed = 0\n",
    "\n",
    "                \n",
    "\n",
    "        elif sentence_pointer < len(sentence_words) and (fuzz.token_sort_ratio(word_in_tuple, sentence_words[sentence_pointer]) >= 80 or fuzz.token_sort_ratio(word_in_tuple, sentence_words[sentence_pointer].replace(\"-\", \"\", 1)) >= 80):\n",
    "            # If no hyphenation, match the word as usual\n",
    "            in_matching = True\n",
    "\n",
    "            words_to_highlight.append(word_tuples[i])\n",
    "            sentence_pointer += 1  # Move to the next word in the sentence\n",
    "\n",
    "            # Decrement grace period counter if it's still active\n",
    "            if grace_period_counter > 0:\n",
    "                grace_period_counter -= 1\n",
    "        else:\n",
    "            \n",
    "            words_passed += 1\n",
    "\n",
    "            if (in_matching and words_passed > max_word_distance) or (grace_period_counter > 0):\n",
    "                sentence_pointer = 0\n",
    "                grace_period_counter = init_grace_period_counter  # Reset the grace period\n",
    "                words_to_highlight = []\n",
    "\n",
    "                in_matching = False\n",
    "                words_passed = 0\n",
    "\n",
    "        # If we've matched the entire sentence, break out of the loop\n",
    "        if sentence_pointer == len(sentence_words):\n",
    "            break\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    return words_to_highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Function to calculate Euclidean distance between two points\n",
    "def euclidean_distance(box1, box2):\n",
    "    x1, y1 = (box1[0] + box1[2]) / 2, (box1[1] + box1[3]) / 2\n",
    "    x2, y2 = (box2[0] + box2[2]) / 2, (box2[1] + box2[3]) / 2\n",
    "    return math.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)\n",
    "\n",
    "# Function to find the closest word\n",
    "def find_closest_word(word_tuple, previous_list):\n",
    "    min_distance = float('inf')\n",
    "    closest_word = None\n",
    "    for candidate_tuple in previous_list:\n",
    "        distance = euclidean_distance(word_tuple, candidate_tuple)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_word = candidate_tuple\n",
    "    return closest_word\n",
    "\n",
    "# Main function to get the closest words from the lists\n",
    "def get_closest_words(lists_of_tuples):\n",
    "    # Remove empty lists in case they exist\n",
    "    lists_of_tuples = [lst for lst in lists_of_tuples if lst]\n",
    "\n",
    "    # If no lists, return an empty list\n",
    "    if not lists_of_tuples:\n",
    "        return []\n",
    "    \n",
    "    # Sort lists by length in descending order\n",
    "    lists_of_tuples.sort(key=len, reverse=True)\n",
    "\n",
    "    # Start with the longest list\n",
    "    result = lists_of_tuples[0]\n",
    "\n",
    "    # Iterate over the words in the result\n",
    "    for i in range(1, len(lists_of_tuples)):\n",
    "        previous_list = lists_of_tuples[i]\n",
    "        new_result = []\n",
    "        for word_tuple in result:\n",
    "            closest_word = find_closest_word(word_tuple, previous_list)\n",
    "            if closest_word:\n",
    "                new_result.append(closest_word)\n",
    "        result = new_result\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_words_to_highlight_v2(sentence, word_tuples):\n",
    "\n",
    "    grace_periods = range(2,5)\n",
    "    all_results = []\n",
    "\n",
    "    # Collect results from different grace periods\n",
    "    for grace in grace_periods:\n",
    "        result = find_words_to_highlight(sentence, word_tuples, grace_period_counter=grace)\n",
    "        all_results.append(result)\n",
    "\n",
    "    # Combine results and choose the best matching words\n",
    "    closest_words = get_closest_words(all_results)\n",
    "\n",
    "    return closest_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = \"openai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_highlights = []\n",
    "all_summaries = []\n",
    "\n",
    "for page in tqdm(doc):\n",
    "    # Get text from page\n",
    "    text = page.get_text(\"text\")\n",
    "\n",
    "    # # Replace \\n with spacesq\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "    # # Replace \"- \" with \"\"\n",
    "    text = text.replace(\"- \", \"\")\n",
    "\n",
    "    # Initialise stop flag\n",
    "    stop = False\n",
    "\n",
    "    word_tuples = page.get_text(\"words\", flags=pymupdf.TEXT_DEHYPHENATE)\n",
    "\n",
    "    if CONFIG == \"openai\":\n",
    "        message = client.beta.threads.messages.create(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            content=text\n",
    "        )\n",
    "\n",
    "        run = client.beta.threads.runs.create_and_poll(\n",
    "            thread_id=thread.id,\n",
    "            assistant_id=OPENAI_ASST_ID\n",
    "        )\n",
    "\n",
    "        if run.status == 'completed': \n",
    "            messages = client.beta.threads.messages.list(\n",
    "                thread_id=thread.id\n",
    "            )\n",
    "            response = json.loads(messages.data[0].content[0].text.value)\n",
    "            \n",
    "            summary = response[\"summary\"]\n",
    "            highlights = response[\"highlights\"]\n",
    "            stop = response[\"stop\"]\n",
    "        else:\n",
    "            print(run.status)\n",
    "    else:\n",
    "        summary = \"Just a test summary\"\n",
    "        highlights =  [\"Just a test highlighting\"]\n",
    "\n",
    "    all_highlights.extend(highlights)\n",
    "    all_summaries.append(summary)\n",
    "\n",
    "    failed_highlights = []\n",
    "\n",
    "    for sentence_to_highlight in highlights:\n",
    "\n",
    "        rects = page.search_for(sentence_to_highlight)\n",
    "\n",
    "        if rects != []:\n",
    "            page.add_highlight_annot(rects)\n",
    "            continue\n",
    "        \n",
    "        words_to_highlight = find_words_to_highlight_v2(sentence_to_highlight, word_tuples)\n",
    "        if words_to_highlight is None or len(words_to_highlight) == 0:\n",
    "            failed_highlights.append(sentence_to_highlight)\n",
    "            continue\n",
    "        line_bounding_boxes = get_bounding_boxes(words_to_highlight)\n",
    "\n",
    "        for line_index, bounding_box in line_bounding_boxes.items():\n",
    "            min_x, min_y, max_x, max_y = bounding_box\n",
    "            p1 = pymupdf.Point(min_x, min_y)\n",
    "            p2 = pymupdf.Point(max_x, max_y)\n",
    "            page.add_highlight_annot(quads=[p1, p2])\n",
    "\n",
    "    if len(failed_highlights) > 0:\n",
    "        print(f\"Failed to highlight {len(failed_highlights)}/{len(highlights)} sentences\")\n",
    "        print(failed_highlights)\n",
    "\n",
    "    # Add summary as comment\n",
    "    page.add_text_annot((10, 10), \"Summary: \" + summary, icon=\"Comment\")\n",
    "\n",
    "    if stop:\n",
    "        break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the modified PDF\n",
    "doc.save(\"examples/output/output5.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
